<!DOCTYPE html5>
<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta author="Clémence">
    <meta author="Sylvain">
    <meta author="Nahor">
    <meta charset="utf-8">
    <title>Chef-d'Œuvre du M2 IGAI 2019/2020</title>
    <link rel="stylesheet" type="text/css" href="siteWeb_fichiers/layout.css">
    <link href="siteWeb_fichiers/css.css" rel="stylesheet">
</head>


<body>
	<div class="topnav">
	<div class="maintitle"><a name="top" href="#top">Ré-identification de véhicule</a></div>
	<a href="#refs">RÉFÉRENCES ET LIVRABLES</a>
	<a href="#productions">PRODUCTIONS</a>
	<a href="#Pres">PRÉSENTATION</a>
	<a href="#banner">ACCUEIL</a>
 </div>

<main>

<div id="banner" class="banner">
</div>

<div class="maincontent">

<section id="Pres">
    <a name="Pres">
    <h3><span class="titlebox">PRÉSENTATION</span></h3></a><br>
    <p>
	Dans le cadre du <a href="http://departement-informatique.univ-tlse3.fr/master-igai/" target="_blank">Master 2 Informatique Graphique et Analyse d'Images</a> de l'Université Paul Sabatier de Toulouse, l'équipe Re-Id s'est consacrée à ré-identifier des véhicules dans un ensemble de vidéos par apprentissage profond.
 Le principe général du Chef-d'Oeuvre consiste en l'implantation de
travaux de recherches proposés récemment. L'équipe a répondu au sujet proposé par
Alain Crouzil, enseignant chercheur à l'Institut de
Recherche dans l'équipe <a href="https://www.irit.fr/departement/signaux-images/tci/" target="_blank">Traitement et Compréhension d'Images</a> .
	</p>

	<p>
    La multiplication des caméras de surveillance permet de fournir de très nombreuses vidéos susceptibles de contenir des informations importantes
    pour les enquêtes liées à des activités criminelles ou terroristes. Mais l'analyse de ces vidéos, qui peuvent atteindre plusieurs milliers
     d'heures d'enregistrements, est une tâche difficile qui nécessite beaucoup de temps et d'attention de la part des enquêteurs.
     Il y a donc un besoin urgent d'outils pour faciliter leurs recherches.
    La ré-identification de véhicules et, surtout, la ré-identification de personnes sont des domaines d'application de la vision
     par ordinateur qui ont fait l'objet de nombreux travaux récents faisant appel aux techniques d'apprentissage profond.
     Liu et al. <a href="#refs">[1]</a> ont été les premiers à proposer l'utilisation d'un réseau de neurones convolutif pour la ré-identification de véhicules.
     Ils ont également constitué le jeu de données <a href="https://vehiclereid.github.io/VeRi/"target="_blank">VeRI</a> .
	</p>

	<p>
	La technique utilisé dans ce projet est la méthode FACT. Cette méthode combine des descripteurs de couleurs avec des descripteurs SIFT ainsi que
  les sorties d'une couche du réseau de neurones GoogleNet. Le projet est réalisé en Python en utilisant les bibliothèques OpenCv et Keras.
 Il peut-être récupéré <a href="https://github.com/SylvainDeker/Vehicle-ReIdentification.git" target="_blank">ici</a>.
	</p>

<table cellspacing="15">
    	<tbody><tr>
    		<td><h4></h4></td>
    		<td><h4>Quelques exemples du jeu de donnée. </h4></td>
    		<td><h4></h4></td>
    	</tr>
    	<tr>
    		<td><div class="zoom"><img src="siteWeb_fichiers/0001_c001_00016450_0.jpg" alt="Jaune" width="300"></a></div></td>
    		<td><div class="zoom"><img src="siteWeb_fichiers/0003_c001_00021480_0.jpg" alt="Rouge" width="300"></a></div></td>
    		<td><div class="zoom"><img src="siteWeb_fichiers/0011_c017_00088445_0.jpg" alt="Camion" width="300"></a></div></td>
    	</tr>

    </tbody></table>

</section>

<!-- Description détaillée -->

<section id="productions">
<a name="ombre">
    <h3><span class="titlebox">PRODUCTIONS</span></h3></a><br>
<p>
La méthode de calcul d'ombrage <i>Moment based Shadow Mapping</i> (MSM) est comparée ici aux méthodes <i>Percentage Closer
Filtering</i> (PCF) comme méthode de référence et <i>Variance Shadow Mapping</i> (VSM) comme méthode intermédiaire, basée elle aussi
sur des moments statistiques. L'objectif est ici de voir comment se comportent ces trois méthodes. La PCF donne de très
bon résultats mais souffre d'un problème de performance, pouvant être problèmatique dans un contexte de rendu temps réel.
L'objectif de la MSM sera de fournir un rendu le plus proche possible de la PCF, avec de meilleurs performances. Cette approche
se base sur la VSM offrant d'excellentes performances mais des défauts visuels problématiques, comme de la fuite de lumière.
</p>

<section id="ombre">
		<a name="ombre">
    <h4><span class="titlebox2">OMBRAGE</span></h4></a>

    <table cellspacing="30">
    	<tbody><tr>
    		<td><h4><i>Percentage Closer Filtering</i> [2]</h4></td>
    		<td><h4><i>Variance Shadow Maps</i> [3]</h4></td>
    		<td><h4><i>Moment Shadow Mapping</i> [1]</h4></td>
    	</tr>
    	<tr>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/testPCF_3.png" target="_blank"><img src="siteWeb_fichiers/testPCF_3.png" alt="PCF" width="300"></a></div><br>Aucune fuite de lumière</td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/testVSM_3.png" target="_blank"><img src="siteWeb_fichiers/testVSM_3.png" alt="VSM" width="300"></a></div><br>Fuite de lumière importante</td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/testMSM_3.png" target="_blank"><img src="siteWeb_fichiers/testMSM_3.png" alt="MSM" width="300"></a></div><br>Très légère fuite de lumière</td>
    	</tr>
    	<tr>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/PCF_KS9_SD_2dot4_DB0dot016_1.png" target="_blank"><img src="siteWeb_fichiers/PCF_KS9_SD_2dot4_DB0dot016_1.png" alt="PCF" width="300"></a></div></td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/VSM_KS9_SD2dot4_MinVar0dot000002_1.png" target="_blank"><img src="siteWeb_fichiers/VSM_KS9_SD2dot4_MinVar0dot000002_1.png" alt="VSM" width="300"></a></div></td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/MSM_KS9_SD2dot4_MB3x10-5_DB0dot001_1.png" target="_blank"><img src="siteWeb_fichiers/MSM_KS9_SD2dot4_MB3x10-5_DB0dot001_1.png" alt="MSM" width="300"></a></div></td>
    	</tr>
    </tbody></table>

</section>

<section id="transparence">
		<a name="Transparence">
    <h4><span class="titlebox2">TRANSPARENCE</span></h4></a>

<p>
La méthode de calcul de transparence <i>Moment based Order Independent Transparency</i> (MBOIT) est comparée ici
aux méthodes <i>depth peeling</i> comme méthode de référence et <i>Weighted Blended Order Independent Transparency</i>
(WBOIT) comme méthode intermédiaire. L'objectif est ici de voir comment se comportent ces trois méthodes. Le <i>depth peeling</i>

produits de bon résultats mais souffre d'un problème de performance et
nécessite d'ếtre paramétré par le nombre de couches transparentes à
représenter.
Le nombre de passes de rendu réalisé, proportionnel à la complexité de
la scène en terme de surfaces transparentes recouvertes successivement,
explique les limites de la méthode dans le contexte du rendu temps réel.
 L'objectif de la méthode MBOIT sera de fournir un rendu le plus proche
possible du <i>depth peeling</i>, avec de meilleurs
 performances. La méthode WBOIT a l'avantage d'être performante, mais la
 qualité des résultats est directement dépendante de la configuration de
 la scène et de la fonction de coût utilisée.
</p>


    <table cellspacing="15">
    	<tbody><tr>
    		<td><h4><i>Depth Peeling</i> [5]</h4></td>
    		<td><h4><i>Weighted Blended Order-Independent Transparency</i> [6]</h4></td>
    		<td><h4><i>Moment-Based Order Independent Transparency</i> [4]</h4></td>
    	</tr>
    	<tr>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/OIT-DepthPeeling-test7.png" target="_blank"><img src="siteWeb_fichiers/OIT-DepthPeeling-test7.png" alt="DP" width="300"></a></div></td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/OIT-WBOIT-test7.png" target="_blank"><img src="siteWeb_fichiers/OIT-WBOIT-test7.png" alt="WBOIT" width="300"></a></div></td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/OIT-MBOIT-test7.png" target="_blank"><img src="siteWeb_fichiers/OIT-MBOIT-test7.png" alt="MBOIT" width="300"></a></div></td>
    	</tr>
    	<tr>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/OIT-DepthPeeling-30.png" target="_blank"><img src="siteWeb_fichiers/OIT-DepthPeeling-30.png" alt="DP" width="300"></a></div></td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/OIT-WBOIT-16-150-6.png" target="_blank"><img src="siteWeb_fichiers/OIT-WBOIT-16-150-6.png" alt="WBOIT" width="300"></a></div></td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/OIT-MBOIT-0,30-5%5E5-4pm.png" target="_blank"><img src="siteWeb_fichiers/OIT-MBOIT-030-55-4pm.png" alt="MBOIT" width="300"></a></div></td>
    	</tr>
    </tbody></table>
</section>

<section id="comparaison">
		<a name="comparaison">
    <h4><span class="titlebox2">COMPARAISON</span></h4></a>
    <p>
Nous proposons également un module de comparaison d'images à l'aide d'opérateurs de différence dans trois
espaces de couleurs HSV, L*a*b* et niveau de gris. L'espace de couleur HSV(Hue Saturation Value) nous permet de séparer
la teinte, la saturation et la luminosité. L'espace de couleur L*a*b* est un espace de couleur où la répartition des
couleurs se rapproche de la perception des écarts de couleur par le système visuel humain. Voici un exemple de différence
en niveau de gris obtenu par la formule de conversion en luminosité pour mettre en évidence les fuites de lumières
causées par les différentes méthodes de calcul d'ombrage.
</p>

<table cellspacing="35">
    	<tbody><tr>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/T_rexPCF.png" target="_blank"><img src="siteWeb_fichiers/T_rexPCF.png" alt="PCF" width="300"></a></div><br>PCF</td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/T_rexMSM.png" target="_blank"><img src="siteWeb_fichiers/T_rexMSM.png" alt="MSM" width="300"></a></div><br>MSM</td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/T_rexVSM.png" target="_blank"><img src="siteWeb_fichiers/T_rexVSM.png" alt="VSM" width="300"></a></div><br>VSM</td>
    	</tr>
    	<tr>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/diffGrisPCF_MSM.png" target="_blank"><img src="siteWeb_fichiers/diffGrisPCF_MSM.png" alt="PCF_MSM" width="300"></a></div><br>Différence PCF/MSM</td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/diffGrisPCF_VSM.png" target="_blank"><img src="siteWeb_fichiers/diffGrisPCF_VSM.png" alt="PCF_VSM" width="300"></a></div><br>Différence PCF/VSM</td>
    		<td><div class="zoom"><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/images/diffGrisMSM_VSM.png" target="_blank"><img src="siteWeb_fichiers/diffGrisMSM_VSM.png" alt="MSM_VSM" width="300"></a></div><br>Différence MSM/VSM</td>
    	</tr>
    </tbody></table>

</section>
</section>

</div>
</main>


<!-- Auteurs, références et livrables -->
<footer id="refs">
    <table cellspacing="12">
        <tbody><tr>
            <td><h2>L'équipe</h2></td>
            <td><h2><b>Références</b></h2></td>
            <td><b>Phases</b></td>
            <td><b>Rapports</b></td>
            <td><b>Diapositives</b></td>
        </tr>
        <tr>

            <td><b>Courdy-Bahsoun Clémence</b></td>
            <td><a href="https://ieeexplore.ieee.org/document/7553002" target="_blank">
                [1] X. Liu, W. Liu, H. Ma, H. Fu, <i>Large-scale vehicle re-identification in urban surveillance videos</i> (2016)</a></td>
            <td>Méthodes et Algorithmes</td>
            <td><a name="rapports" href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-LMA.pdf" target="_blank"><img src="siteWeb_fichiers/report.png" alt="Report logo" class="center" width="25"></a></td>
            <td><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-LMA-Support.pdf" target="_blank"><img src="siteWeb_fichiers/support.png" alt="Report logo" class="center" width="25"></a></td>
        </tr>
        <tr>
            <td><b>Deker Sylvain</b></td>
            <td><a href="https://arxiv.org/pdf/1804.02767" target="_blank">
                [2] J. Redmon, A. Farhadi, <i>YOLOv3: An Incremental Improvement</i> (2018)</a></td>
            <td>Spécifications</td>
            <td><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-Spec.pdf" target="_blank"><img src="siteWeb_fichiers/report.png" alt="Report logo" class="center" width="25"></a></td>
            <td><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-Spec-Support.pdf" target="_blank"><img src="siteWeb_fichiers/support.png" alt="Report logo" class="center" width="25"></a></td>
        </tr>
        <tr>
            <td><b>Moussa Nahor</b></td>
            <td><a href="https://arxiv.org/pdf/1506.08959" target="_blank">
                [3] L. Yang, P. Luo, C. C. Loy, X. Tang, <i>A Large-Scale Car Dataset for Fine-Grained Categorization and Verification</i> (2015)</a></td>
            <td>Conception</td>
            <td><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-Conception.pdf" target="_blank"><img src="siteWeb_fichiers/report.png" alt="Report logo" class="center" width="25"></a></td>
            <td><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-Conception-Support.pdf" target="_blank"><img src="siteWeb_fichiers/support.png" alt="Report logo" class="center" width="25"></a></td>
        </tr>
        <tr>
            <td><b></b></td>
            <td></td>
			<td>Recette</td>
            <td><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-Recette.pdf" target="_blank"><img src="siteWeb_fichiers/report.png" alt="Report logo" class="center" width="25"></a></td>
            <td><a href="http://fsi-dpt-info.univ-tlse3.fr/master-igai/2018-g1/reports/MBR-Recette-Support.pdf" target="_blank"><img src="siteWeb_fichiers/support.png" alt="Report logo" class="center" width="25"></a></td>
        </tr>
        <tr>
            <td><b></b></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
        <tr>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
            <td></td>
        </tr>
    </tbody></table>
</footer>




</body></html>
